# Redis

---

## 单线程

Redis的单线程是指处理网络请求的时候只使用一个线程，所以不需要考虑并发的安全性，也不用考虑各种锁的问题。但一个正式的Redis Server运行的时候还是使用的多线程，即除网络请求处理模块意外的其他模块一般是使用的多线程

## 快

- 绝大部分请求都是纯粹的内存操作，且数据存储在内存中，结构类似hashmap，hashmap的优势即根据键值快速查找，时间复杂度为O(1)

- 数据结构简单

- 采用单线程处理网络请求，避免多线程的线程上下文切换问题和锁的争夺与等待问题

- 使用IO多路复用模型(非阻塞IO)

- 底层模型 -> Redis自己构建了VM机制，因为一般的系统调用系统函数会浪费一定的时间去移动和请求

  ### IO多路复用

  当多个redis客户端与redis服务器的网络连接模块保持TCP连接，客户端会不定时的发送请求给服务器，当有一个redis客户端发起请求，会触发unix系统的epoll (windows系统的select) 这样的系统调用，Redis的I/O 多路复用模块封装了底层的epoll这样的 I/O 多路复用函数，然后转发到相应的事件处理器。

  文件事件处理器使用 I/O 多路复用模块同时监听多个 FD（文件描述符），当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器。

  虽然整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单。



## 数据类型

常用数据类型：

​	string、list、set、sorted set、hash

## 事务

 **可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞**

Redis事务的作用： 一个队列中，一次性、顺序性、排他性的执行一系列命令 

使用mutil命令开启事务，后续的所有命令都会进入命令队列，但并没有立即执行，而是在调用exec命令时执行

开启事务后可通过discard命令放弃事务，

**redis对事务是部分支持的，如果是在入队时报错，那么都不会执行；在非入队时报错，那么成功的就会成功执行**，即不支持事务的原子性

**Redis事务的三大特性：**

-  单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 
-  没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题 
-  不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 

## 特性

### 流水线

目的： **通过减少客户端与服务器之间的通信次数来提高程序的执行效率**。 类似于channel和buffer机制

在一般情况下，用户每执行一个 Redis 命令，客户端和服务器都需要进行一次通信：客户端向服务器发送命令请求，而服务器则会将执行命令所得的命令回复返回给客户端；

在大多数情况下， 执行命令时的绝大部分时间都耗费在了发送命令和接收回复的过程上，因此减少客户端与服务器之间的通信次数，可以有效地提高程序的执行效率；

流水线可以将多条命令打包一起发送，并且在一次回复中接收所有被执行命令的结果，使用这个功能可以有效地提升程序在执行多条命令时的效率； 

### 发布/订阅

- 频道的订阅与发布

  ​	Redis 的SUBSCRIBE命令可以让客户端订阅任意数量的频道， 每当有新信息发送到被订阅的频道时， 信息就会被发送给所有订阅指定频道的客户端。 

- 模式的订阅与发布

  ​	当使用 PUBLISH命令发送信息到某个频道时， 不仅所有订阅该频道的客户端会收到信息， 如果有某个/某些模式和这个频道匹配的话， 那么所有订阅这个/这些频道的客户端也同样会收到信息。 

### 持久化

快照持久化  -> 会发生数据丢失问题

AOF持久化 -> 向记录文件中追加操作信息，随着记录的增长，文件不断变大，导致性能下降，可通过设置自动清理来限制记录文件的大小 -> 适用于需要数据强可靠性的场景，如金融业务

### 淘汰机制

> volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰

> volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰

> volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰

> allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰

> allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰

> no-enviction（驱逐）：禁止驱逐数据

## Redis实现分布式锁

https://zhuanlan.zhihu.com/p/69681662

## Redis缓存问题

1. 缓存穿透
定义：缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。
方法：
1. 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
2. 对于空的key返回一个特定的value,例如“&&”.在返回这个&&值的时候，我们的应用就可以认为这是不存在的key，那我们的应用就可以决定是否继续等待继续访问，还是放弃掉这次操作。如果继续等待访问，过一个时间轮询点后，再次请求这个key，如果取到的值不再是&&，则可以认为这时候key有值了，从而避免了透传到数据库，从而把大量的类似请求挡在了缓存之中。

2.缓存雪崩
定义：缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。
解决方法：缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

3.缓存击穿
对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。
1.使用互斥锁(mutex key)
业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。

2. “提前”使用互斥锁(mutex key)：
在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。
3. 永不过期

4.如何解决DB和缓存一致性问题？
答：当修改了数据库后，有没有及时修改缓存。修改数据库成功，而修改缓存失败的情况，最主要就是缓存服务器挂了。而因为网络问题引起的没有及时更新，可以通过重试机制来解决。而缓存服务器挂了，请求首先自然也就无法到达，从而直接访问到数据库。那么我们在修改数据库后，无法修改缓存，这时候可以将这条数据放到数据库中，同时启动一个异步任务定时去检测缓存服务器是否连接成功，一旦连接成功则从数据库中按顺序取出修改数据，依次进行缓存最新值的修改。